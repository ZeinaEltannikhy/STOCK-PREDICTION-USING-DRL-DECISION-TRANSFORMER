{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stable-baselines3 in /opt/anaconda3/lib/python3.10/site-packages (2.4.0)\n",
      "Requirement already satisfied: gym in /opt/anaconda3/lib/python3.10/site-packages (0.26.2)\n",
      "Collecting yfinance\n",
      "  Downloading yfinance-0.2.51-py2.py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.47.1-py3-none-any.whl.metadata (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m361.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting textblob\n",
      "  Downloading textblob-0.18.0.post0-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting newsapi-python\n",
      "  Downloading newsapi_python-0.2.7-py2.py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting praw\n",
      "  Downloading praw-7.8.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting asyncpraw\n",
      "  Downloading asyncpraw-7.8.1-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: gymnasium<1.1.0,>=0.29.1 in /opt/anaconda3/lib/python3.10/site-packages (from stable-baselines3) (1.0.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.20 in /opt/anaconda3/lib/python3.10/site-packages (from stable-baselines3) (1.26.4)\n",
      "Requirement already satisfied: torch>=1.13 in /opt/anaconda3/lib/python3.10/site-packages (from stable-baselines3) (2.5.1)\n",
      "Requirement already satisfied: cloudpickle in /opt/anaconda3/lib/python3.10/site-packages (from stable-baselines3) (2.2.1)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.10/site-packages (from stable-baselines3) (2.2.2)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.10/site-packages (from stable-baselines3) (3.8.4)\n",
      "Requirement already satisfied: gym_notices>=0.0.4 in /opt/anaconda3/lib/python3.10/site-packages (from gym) (0.0.8)\n",
      "Requirement already satisfied: requests>=2.31 in /opt/anaconda3/lib/python3.10/site-packages (from yfinance) (2.32.2)\n",
      "Collecting multitasking>=0.0.7 (from yfinance)\n",
      "  Downloading multitasking-0.0.11-py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: lxml>=4.9.1 in /opt/anaconda3/lib/python3.10/site-packages (from yfinance) (5.2.1)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in /opt/anaconda3/lib/python3.10/site-packages (from yfinance) (3.10.0)\n",
      "Requirement already satisfied: pytz>=2022.5 in /opt/anaconda3/lib/python3.10/site-packages (from yfinance) (2024.1)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in /opt/anaconda3/lib/python3.10/site-packages (from yfinance) (2.4.2)\n",
      "Collecting peewee>=3.16.2 (from yfinance)\n",
      "  Downloading peewee-3.17.8.tar.gz (948 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m948.2/948.2 kB\u001b[0m \u001b[31m895.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: beautifulsoup4>=4.11.1 in /opt/anaconda3/lib/python3.10/site-packages (from yfinance) (4.12.2)\n",
      "Collecting html5lib>=1.1 (from yfinance)\n",
      "  Downloading html5lib-1.1-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.24.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.27.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.10/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.10/site-packages (from transformers) (2023.10.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.5-cp310-cp310-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/lib/python3.10/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: nltk>=3.8 in /opt/anaconda3/lib/python3.10/site-packages (from textblob) (3.8.1)\n",
      "Collecting prawcore<3,>=2.4 (from praw)\n",
      "  Downloading prawcore-2.4.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting update_checker>=0.18 (from praw)\n",
      "  Downloading update_checker-0.18.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in /opt/anaconda3/lib/python3.10/site-packages (from praw) (1.8.0)\n",
      "Collecting aiofiles (from asyncpraw)\n",
      "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: aiohttp<4 in /opt/anaconda3/lib/python3.10/site-packages (from asyncpraw) (3.9.5)\n",
      "Collecting aiosqlite<=0.17.0 (from asyncpraw)\n",
      "  Downloading aiosqlite-0.17.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting asyncprawcore<3,>=2.4 (from asyncpraw)\n",
      "  Downloading asyncprawcore-2.4.0-py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.10/site-packages (from aiohttp<4->asyncpraw) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.10/site-packages (from aiohttp<4->asyncpraw) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.10/site-packages (from aiohttp<4->asyncpraw) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.10/site-packages (from aiohttp<4->asyncpraw) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.10/site-packages (from aiohttp<4->asyncpraw) (1.9.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/anaconda3/lib/python3.10/site-packages (from aiohttp<4->asyncpraw) (4.0.3)\n",
      "Requirement already satisfied: typing_extensions>=3.7.2 in /opt/anaconda3/lib/python3.10/site-packages (from aiosqlite<=0.17.0->asyncpraw) (4.11.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.10/site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /opt/anaconda3/lib/python3.10/site-packages (from gymnasium<1.1.0,>=0.29.1->stable-baselines3) (0.0.4)\n",
      "Requirement already satisfied: six>=1.9 in /opt/anaconda3/lib/python3.10/site-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
      "Requirement already satisfied: webencodings in /opt/anaconda3/lib/python3.10/site-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.3.1)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.10/site-packages (from nltk>=3.8->textblob) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.10/site-packages (from nltk>=3.8->textblob) (1.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.10/site-packages (from pandas->stable-baselines3) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.10/site-packages (from pandas->stable-baselines3) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.10/site-packages (from requests>=2.31->yfinance) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.10/site-packages (from requests>=2.31->yfinance) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.10/site-packages (from requests>=2.31->yfinance) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.10/site-packages (from requests>=2.31->yfinance) (2024.6.2)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.13->stable-baselines3) (1.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.10/site-packages (from matplotlib->stable-baselines3) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.10/site-packages (from matplotlib->stable-baselines3) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.10/site-packages (from matplotlib->stable-baselines3) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.10/site-packages (from matplotlib->stable-baselines3) (1.4.4)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/lib/python3.10/site-packages (from matplotlib->stable-baselines3) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.10/site-packages (from matplotlib->stable-baselines3) (3.0.9)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.10/site-packages (from jinja2->torch>=1.13->stable-baselines3) (2.1.3)\n",
      "Downloading yfinance-0.2.51-py2.py3-none-any.whl (104 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.7/104.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.47.1-py3-none-any.whl (10.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading textblob-0.18.0.post0-py3-none-any.whl (626 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m626.3/626.3 kB\u001b[0m \u001b[31m984.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading newsapi_python-0.2.7-py2.py3-none-any.whl (7.9 kB)\n",
      "Downloading praw-7.8.1-py3-none-any.whl (189 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.3/189.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading asyncpraw-7.8.1-py3-none-any.whl (196 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.4/196.4 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiosqlite-0.17.0-py3-none-any.whl (15 kB)\n",
      "Downloading asyncprawcore-2.4.0-py3-none-any.whl (19 kB)\n",
      "Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.27.0-py3-none-any.whl (450 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m450.5/450.5 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading multitasking-0.0.11-py3-none-any.whl (8.5 kB)\n",
      "Downloading prawcore-2.4.0-py3-none-any.whl (17 kB)\n",
      "Downloading safetensors-0.4.5-cp310-cp310-macosx_11_0_arm64.whl (381 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.21.0-cp39-abi3-macosx_11_0_arm64.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
      "Downloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Building wheels for collected packages: peewee\n",
      "  Building wheel for peewee (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for peewee: filename=peewee-3.17.8-cp310-cp310-macosx_11_0_arm64.whl size=263409 sha256=4aa066750f29c2c02a8b5c0ef3d4977220e0ef9ed60e2643a74e7ed6edf6f2c9\n",
      "  Stored in directory: /Users/mohamedeldagla/Library/Caches/pip/wheels/75/79/e5/8838db0594cc6c587142fd2563356392ade6255c5930411069\n",
      "Successfully built peewee\n",
      "Installing collected packages: peewee, multitasking, safetensors, html5lib, aiosqlite, aiofiles, update_checker, textblob, prawcore, newsapi-python, huggingface-hub, yfinance, tokenizers, praw, asyncprawcore, transformers, asyncpraw\n",
      "Successfully installed aiofiles-24.1.0 aiosqlite-0.17.0 asyncpraw-7.8.1 asyncprawcore-2.4.0 html5lib-1.1 huggingface-hub-0.27.0 multitasking-0.0.11 newsapi-python-0.2.7 peewee-3.17.8 praw-7.8.1 prawcore-2.4.0 safetensors-0.4.5 textblob-0.18.0.post0 tokenizers-0.21.0 transformers-4.47.1 update_checker-0.18.0 yfinance-0.2.51\n",
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.10/site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in /opt/anaconda3/lib/python3.10/site-packages (0.20.1)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.5.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.10/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/lib/python3.10/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.10/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.10/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/lib/python3.10/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.10/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/anaconda3/lib/python3.10/site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Downloading torchaudio-2.5.1-cp310-cp310-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m903.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torchaudio\n",
      "Successfully installed torchaudio-2.5.1\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.10/site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/anaconda3/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/anaconda3/lib/python3.10/site-packages (from scikit-learn) (1.13.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.10/site-packages (from scikit-learn) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.10/site-packages (from scikit-learn) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install stable-baselines3 gym yfinance transformers textblob newsapi-python praw asyncpraw\n",
    "!pip install torch torchvision torchaudio  # Ensure PyTorch is installed\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from textblob import TextBlob\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3 import PPO, A2C\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged Data:\n",
      "         Date Symbol  Adj Close      Close       High        Low       Open  \\\n",
      "0  04/01/2010    MMM  44.016720  69.414719  69.774246  69.122070  69.473244   \n",
      "1  05/01/2010    MMM  43.741032  68.979935  69.590302  68.311035  69.230766   \n",
      "2  06/01/2010    MMM  44.361347  69.958191  70.735786  69.824417  70.133781   \n",
      "3  07/01/2010    MMM  44.393150  70.008362  70.033447  68.662209  69.665550   \n",
      "4  08/01/2010    MMM  44.705982  70.501671  70.501671  69.648827  69.974915   \n",
      "\n",
      "      Volume                                            content  sentiment  \n",
      "0  3640265.0  r/Stocks Daily Discussion & Fundamentals Frida...   0.000000  \n",
      "1  3405012.0  ASML is this weird green color today, that can...  -0.138095  \n",
      "2  6301126.0                 Even AMD is a little bit up today!  -0.234375  \n",
      "3  5346240.0  I‚Äôm thankful for one of the strongest runs i...   0.000000  \n",
      "4  4073337.0  [From September 2021](https://i.imgur.com/nCzn...   0.209855  \n"
     ]
    }
   ],
   "source": [
    "# Path to your merged CSV file\n",
    "file_path = 'merged_stock_news_data.csv'\n",
    "\n",
    "# Load the merged data\n",
    "merged_data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows\n",
    "print(\"Merged Data:\")\n",
    "print(merged_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of dates failed to parse: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kx/tf5bbbjj20gckm28dqr1ftzm0000gn/T/ipykernel_26326/2972412978.py:2: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  merged_data['Date'] = pd.to_datetime(merged_data['Date'], infer_datetime_format=True, dayfirst=True, errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "# Convert 'Date' to datetime without specifying the format\n",
    "merged_data['Date'] = pd.to_datetime(merged_data['Date'], infer_datetime_format=True, dayfirst=True, errors='coerce')\n",
    "\n",
    "# Check for any parsing failures\n",
    "num_failed = merged_data['Date'].isnull().sum()\n",
    "print(f\"\\nNumber of dates failed to parse: {num_failed}\")\n",
    "\n",
    "if num_failed > 0:\n",
    "    print(\"Some dates couldn't be parsed. Please check the data for inconsistencies.\")\n",
    "    # Optionally, inspect the rows with NaT\n",
    "    failed_dates = merged_data[merged_data['Date'].isnull()]\n",
    "    print(failed_dates[['Date']])\n",
    "    # Decide on an imputation strategy. For simplicity, we'll drop these rows.\n",
    "    merged_data = merged_data.dropna(subset=['Date']).reset_index(drop=True)\n",
    "    print(f\"Dropped rows with unparsable dates. New data size: {merged_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kx/tf5bbbjj20gckm28dqr1ftzm0000gn/T/ipykernel_26326/845900595.py:13: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_data[['SMA', 'RSI']] = merged_data[['SMA', 'RSI']].fillna(method='bfill').fillna(0)\n"
     ]
    }
   ],
   "source": [
    "def compute_rsi(prices, period=14):\n",
    "    delta = prices.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).fillna(0)\n",
    "    loss = (-delta.where(delta < 0, 0)).fillna(0)\n",
    "    avg_gain = gain.rolling(window=period).mean()\n",
    "    avg_loss = loss.rolling(window=period).mean()\n",
    "    rs = avg_gain / avg_loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    return rsi\n",
    "\n",
    "merged_data['SMA'] = merged_data['Close'].rolling(window=10).mean()\n",
    "merged_data['RSI'] = compute_rsi(merged_data['Close'])\n",
    "merged_data[['SMA', 'RSI']] = merged_data[['SMA', 'RSI']].fillna(method='bfill').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Sentiment Values: 1\n",
      "Filling missing sentiment values with 0 (neutral sentiment).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kx/tf5bbbjj20gckm28dqr1ftzm0000gn/T/ipykernel_26326/1537613443.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_data['sentiment'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "missing_sentiment = merged_data['sentiment'].isnull().sum()\n",
    "print(f\"\\nMissing Sentiment Values: {missing_sentiment}\")\n",
    "if missing_sentiment > 0:\n",
    "    print(\"Filling missing sentiment values with 0 (neutral sentiment).\")\n",
    "    merged_data['sentiment'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data after Sorting:\n",
      "        Date      Close\n",
      "0 2010-01-04  69.414719\n",
      "1 2010-01-04  14.300000\n",
      "2 2010-01-04  69.190002\n",
      "3 2010-01-04  35.450001\n",
      "4 2010-01-04   7.643214\n"
     ]
    }
   ],
   "source": [
    "merged_data = merged_data.sort_values('Date').reset_index(drop=True)\n",
    "print(\"\\nData after Sorting:\")\n",
    "print(merged_data[['Date', 'Close']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockTransformer(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=128, num_layers=2):\n",
    "        super(StockTransformer, self).__init__()\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=hidden_size, nhead=4)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
    "        self.input_fc = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: Tensor of shape (batch_size, seq_len, input_size)\n",
    "        \"\"\"\n",
    "        x = self.input_fc(x)          # (batch_size, seq_len, hidden_size)\n",
    "        x = self.relu(x)\n",
    "        x = x.permute(1, 0, 2)        # (seq_len, batch_size, hidden_size)\n",
    "        x = self.transformer_encoder(x)  # (seq_len, batch_size, hidden_size)\n",
    "        x = x.permute(1, 0, 2)        # (batch_size, seq_len, hidden_size)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsTransformer(nn.Module):\n",
    "    def __init__(self, pretrained_model='bert-base-uncased', hidden_size=128):\n",
    "        super(NewsTransformer, self).__init__()\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(pretrained_model)\n",
    "        self.bert = BertModel.from_pretrained(pretrained_model)\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, texts):\n",
    "        \"\"\"\n",
    "        texts: List of strings\n",
    "        Returns:\n",
    "            embeddings: Tensor of shape (batch_size, hidden_size)\n",
    "        \"\"\"\n",
    "        # Tokenize input texts\n",
    "        encoding = self.tokenizer(texts, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "        input_ids = encoding['input_ids'].to(self.bert.device)\n",
    "        attention_mask = encoding['attention_mask'].to(self.bert.device)\n",
    "        \n",
    "        # Get BERT outputs\n",
    "        with torch.no_grad():  # Freeze BERT parameters\n",
    "            outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_embeddings = outputs.last_hidden_state[:, 0, :]  # CLS token\n",
    "        \n",
    "        # Pass through a fully connected layer\n",
    "        embeddings = self.fc(cls_embeddings)\n",
    "        embeddings = self.relu(embeddings)\n",
    "        return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedTransformer(nn.Module):\n",
    "    def __init__(self, stock_input_size, stock_hidden_size, news_hidden_size, combined_size=256):\n",
    "        super(CombinedTransformer, self).__init__()\n",
    "        self.stock_transformer = StockTransformer(input_size=stock_input_size, hidden_size=stock_hidden_size)\n",
    "        self.news_transformer = NewsTransformer(hidden_size=news_hidden_size)\n",
    "        self.fc = nn.Linear(stock_hidden_size + news_hidden_size, combined_size)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, stock_data, news_texts):\n",
    "        \"\"\"\n",
    "        stock_data: Tensor of shape (batch_size, seq_len, stock_input_size)\n",
    "        news_texts: List of strings\n",
    "        Returns:\n",
    "            combined_embeddings: Tensor of shape (batch_size, combined_size)\n",
    "        \"\"\"\n",
    "        stock_embeddings = self.stock_transformer(stock_data)          # (batch_size, seq_len, stock_hidden_size)\n",
    "        stock_embeddings = stock_embeddings.mean(dim=1)                # (batch_size, stock_hidden_size)\n",
    "        news_embeddings = self.news_transformer(news_texts)            # (batch_size, news_hidden_size)\n",
    "        combined = torch.cat((stock_embeddings, news_embeddings), dim=1)  # (batch_size, stock_hidden_size + news_hidden_size)\n",
    "        combined = self.relu(self.fc(combined))                         # (batch_size, combined_size)\n",
    "        return combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTransformerModel(nn.Module):\n",
    "    def __init__(self, combined_size, action_size, hidden_size=256):\n",
    "        super(DecisionTransformerModel, self).__init__()\n",
    "        self.fc = nn.Linear(combined_size, hidden_size)\n",
    "        self.transformer = nn.Transformer(d_model=hidden_size, nhead=4, num_encoder_layers=4)\n",
    "        self.output_layer = nn.Linear(hidden_size, action_size)\n",
    "    \n",
    "    def forward(self, combined_embeddings):\n",
    "        \"\"\"\n",
    "        combined_embeddings: Tensor of shape (batch_size, combined_size)\n",
    "        Returns:\n",
    "            logits: Tensor of shape (batch_size, action_size)\n",
    "        \"\"\"\n",
    "        hidden = torch.relu(self.fc(combined_embeddings))              # (batch_size, hidden_size)\n",
    "        hidden = hidden.unsqueeze(0)                                    # (1, batch_size, hidden_size) for transformer\n",
    "        transformer_output = self.transformer(hidden, hidden)           # (1, batch_size, hidden_size)\n",
    "        transformer_output = transformer_output.squeeze(0)              # (batch_size, hidden_size)\n",
    "        logits = self.output_layer(transformer_output)                  # (batch_size, action_size)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockTradingEnv(Env):\n",
    "    def __init__(self, merged_data, seq_len=10):\n",
    "        super(StockTradingEnv, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.current_step = 0\n",
    "        self.done = False\n",
    "\n",
    "        # Store merged data\n",
    "        self.data = merged_data.reset_index(drop=True)\n",
    "        self.total_steps = len(self.data) - self.seq_len\n",
    "\n",
    "        # Define action and observation space\n",
    "        self.action_space = Discrete(3)  # Actions: Buy, Hold, Sell\n",
    "        self.observation_space = Box(\n",
    "            low=0, high=1, shape=(self.seq_len, 4), dtype=np.float32\n",
    "        )  # [Close, SMA, RSI, sentiment]\n",
    "    \n",
    "        # Initialize state\n",
    "        self.state = self._next_observation()\n",
    "\n",
    "    def _next_observation(self):\n",
    "        if self.current_step + self.seq_len <= len(self.data):\n",
    "            obs = self.data.iloc[self.current_step:self.current_step + self.seq_len][\n",
    "                ['Close', 'SMA', 'RSI', 'sentiment']\n",
    "            ].to_numpy()\n",
    "            return obs\n",
    "        else:\n",
    "            return np.zeros((self.seq_len, 4))  # Zero array if out of bounds\n",
    "\n",
    "    def step(self, action):\n",
    "        self.current_step += 1\n",
    "        if self.current_step >= self.total_steps:\n",
    "            self.done = True\n",
    "        else:\n",
    "            self.done = False\n",
    "\n",
    "        reward = 0\n",
    "        if action == 0:  # Buy\n",
    "            reward = self.data.iloc[self.current_step]['Close'] - self.data.iloc[self.current_step - 1]['Close']\n",
    "        elif action == 2:  # Sell\n",
    "            reward = self.data.iloc[self.current_step - 1]['Close'] - self.data.iloc[self.current_step]['Close']\n",
    "\n",
    "        self.state = self._next_observation()\n",
    "        return self.state, reward, self.done, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        self.done = False\n",
    "        return self._next_observation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialize the environment with merged data\n",
    "env = StockTradingEnv(merged_data=merged_data, seq_len=10)\n",
    "vec_env = DummyVecEnv([lambda: env])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04fc9a5dac104a149c6d29b29206d534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7da5f1919c3f4d6c9a94e9183f24506a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a7d6f4081d642baa2de6a71fea17889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f535dd623d34f95ba58f2909bba65e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43dbd283276a4b43ba152cfcb4440df3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 8. Training and Evaluating the Model\n",
    "# 8.1. Initializing Transformers and Decision Transformer\n",
    "# Define feature sizes\n",
    "stock_input_size = 4          # [Close, SMA, RSI, sentiment]\n",
    "stock_hidden_size = 128\n",
    "news_hidden_size = 128\n",
    "combined_size = 256\n",
    "action_size = env.action_space.n  # 3 actions\n",
    "\n",
    "# Initialize Combined Transformer\n",
    "combined_transformer = CombinedTransformer(\n",
    "    stock_input_size=stock_input_size,\n",
    "    stock_hidden_size=stock_hidden_size,\n",
    "    news_hidden_size=news_hidden_size,\n",
    "    combined_size=combined_size\n",
    ")\n",
    "\n",
    "# Initialize Decision Transformer\n",
    "decision_transformer = DecisionTransformerModel(\n",
    "    combined_size=combined_size,\n",
    "    action_size=action_size,\n",
    "    hidden_size=256\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move models to device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "combined_transformer.to(device)\n",
    "decision_transformer.to(device)\n",
    "\n",
    "# 8.2. Setting Up Optimizer and Loss Function\n",
    "# Define optimizer (combining parameters from both transformers)\n",
    "optimizer = optim.Adam(\n",
    "    list(combined_transformer.parameters()) + list(decision_transformer.parameters()),\n",
    "    lr=1e-4\n",
    ")\n",
    "\n",
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 8.3. Training Loop\n",
    "num_episodes = 5\n",
    "seq_len = 10\n",
    "batch_size = 32 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.10/site-packages (4.66.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import logging\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(filename='training_logs.txt', level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "\n",
    "# Initialize TensorBoard writer\n",
    "writer = SummaryWriter('runs/training_experiment')\n",
    "\n",
    "# Define hyperparameters\n",
    "num_episodes = 100\n",
    "seq_len = 10\n",
    "\n",
    "# Initialize lists to store rewards and losses for analysis\n",
    "episode_rewards = []\n",
    "episode_losses = []\n",
    "\n",
    "# Record the start time of the training\n",
    "training_start_time = time.time()\n",
    "\n",
    "# Create a tqdm progress bar for episodes\n",
    "for episode in tqdm(range(num_episodes), desc=\"Training Episodes\"):\n",
    "    # Record the start time of the episode\n",
    "    episode_start_time = time.time()\n",
    "    \n",
    "    state = env.reset()  # state shape: (seq_len, 4)\n",
    "    total_reward = 0\n",
    "    episode_loss = 0  # To accumulate loss over steps in the episode\n",
    "    \n",
    "    # Iterate over each step within the episode\n",
    "    for step in range(env.total_steps):\n",
    "        # Convert state to tensor and move to device\n",
    "        state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(device)  # (1, seq_len, 4)\n",
    "        \n",
    "        # Prepare news data\n",
    "        news_text = merged_data.iloc[env.current_step]['content']\n",
    "        news_texts = [news_text]  # Batch size 1\n",
    "        \n",
    "        # Get combined embeddings\n",
    "        combined_embeddings = combined_transformer(state_tensor, news_texts)  # (1, combined_size)\n",
    "        \n",
    "        # Get action logits from Decision Transformer\n",
    "        logits = decision_transformer(combined_embeddings)  # (1, action_size)\n",
    "        \n",
    "        # Choose action with highest probability\n",
    "        action = torch.argmax(logits, dim=1).item()\n",
    "        \n",
    "        # Take action in the environment\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "        \n",
    "        # Convert action to tensor\n",
    "        action_tensor = torch.tensor([action]).to(device)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(logits, action_tensor)\n",
    "        episode_loss += loss.item()\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "        \n",
    "        # Update state\n",
    "        state = next_state\n",
    "    \n",
    "    # Record the episode's total reward and average loss\n",
    "    episode_rewards.append(total_reward)\n",
    "    average_loss = episode_loss / (step + 1)\n",
    "    episode_losses.append(average_loss)\n",
    "    \n",
    "    # Calculate the time taken for the episode\n",
    "    episode_end_time = time.time()\n",
    "    episode_duration = episode_end_time - episode_start_time\n",
    "    \n",
    "    # Log metrics\n",
    "    logging.info(f\"Episode {episode+1}/{num_episodes}, Total Reward: {total_reward:.2f}, Avg Loss: {average_loss:.4f}, Time: {episode_duration:.2f}s\")\n",
    "    writer.add_scalar('Total Reward', total_reward, episode)\n",
    "    writer.add_scalar('Average Loss', average_loss, episode)\n",
    "    \n",
    "    # Update the tqdm description with current episode info\n",
    "    tqdm.write(f\"Episode {episode+1}/{num_episodes}, Total Reward: {total_reward:.2f}, Avg Loss: {average_loss:.4f}, Time: {episode_duration:.2f}s\")\n",
    "    \n",
    "    # Save model checkpoints every 10 episodes\n",
    "    if (episode + 1) % 10 == 0:\n",
    "        torch.save(combined_transformer.state_dict(), f'combined_transformer_epoch_{episode+1}.pth')\n",
    "        torch.save(decision_transformer.state_dict(), f'decision_transformer_epoch_{episode+1}.pth')\n",
    "        tqdm.write(f\"Saved model checkpoints at Episode {episode+1}\")\n",
    "\n",
    "# Record the end time of the training\n",
    "training_end_time = time.time()\n",
    "total_training_time = training_end_time - training_start_time\n",
    "\n",
    "print(f\"\\nTraining completed in {total_training_time/60:.2f} minutes.\")\n",
    "\n",
    "# Close the TensorBoard writer\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Evaluating the Model\n",
    "state = env.reset()\n",
    "predicted_actions = []\n",
    "true_labels = []\n",
    "total_reward = 0\n",
    "\n",
    "for step in range(env.total_steps):\n",
    "    # Convert state to tensor and move to device\n",
    "    state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(device)  # (1, seq_len, 4)\n",
    "    \n",
    "    # Prepare news data\n",
    "    news_text = merged_data.iloc[env.current_step]['content']\n",
    "    news_texts = [news_text]  # Batch size 1\n",
    "    \n",
    "    # Get combined embeddings\n",
    "    combined_embeddings = combined_transformer(state_tensor, news_texts)  # (1, combined_size)\n",
    "    \n",
    "    # Get action logits from Decision Transformer\n",
    "    logits = decision_transformer(combined_embeddings)  # (1, action_size)\n",
    "    \n",
    "    # Choose action with highest probability\n",
    "    action = torch.argmax(logits, dim=1).item()\n",
    "    predicted_actions.append(action)\n",
    "    \n",
    "    # Determine true action based on price movement\n",
    "    current_close = merged_data.iloc[env.current_step]['Close']\n",
    "    previous_close = merged_data.iloc[env.current_step - 1]['Close']\n",
    "    if current_close > previous_close:\n",
    "        true_labels.append(0)  # Buy\n",
    "    else:\n",
    "        true_labels.append(2)  # Sell\n",
    "    \n",
    "    # Take action in the environment\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    total_reward += reward\n",
    "    \n",
    "    if done:\n",
    "        break\n",
    "    \n",
    "    # Update state\n",
    "    state = next_state\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(true_labels, predicted_actions)\n",
    "f1 = f1_score(true_labels, predicted_actions, average='weighted')\n",
    "cm = confusion_matrix(true_labels, predicted_actions)\n",
    "\n",
    "print(f\"\\nEvaluation Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Confusion Matrix:\\n{cm}\")\n",
    "\n",
    "# 10. Visualization of Results\n",
    "# Plotting Buy and Sell signals\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(merged_data['Date'], merged_data['Close'], label=\"Close Price\", alpha=0.6)\n",
    "\n",
    "# Identify Buy and Sell signals\n",
    "buy_signals = [i for i, action in enumerate(predicted_actions) if action == 0]\n",
    "sell_signals = [i for i, action in enumerate(predicted_actions) if action == 2]\n",
    "\n",
    "# Adjust indices for plotting (add seq_len offset)\n",
    "buy_signals = [i + seq_len for i in buy_signals]\n",
    "sell_signals = [i + seq_len for i in sell_signals]\n",
    "\n",
    "# Ensure indices are within bounds\n",
    "buy_signals = [i for i in buy_signals if i < len(merged_data)]\n",
    "sell_signals = [i for i in sell_signals if i < len(merged_data)]\n",
    "\n",
    "# Plot Buy and Sell signals\n",
    "plt.scatter(merged_data['Date'].iloc[buy_signals], merged_data['Close'].iloc[buy_signals], color='green', label='Buy Signal', marker='^', alpha=0.7)\n",
    "plt.scatter(merged_data['Date'].iloc[sell_signals], merged_data['Close'].iloc[sell_signals], color='red', label='Sell Signal', marker='v', alpha=0.7)\n",
    "\n",
    "# Customize the plot\n",
    "plt.title(\"Buy and Sell Signals Based on Combined Transformers and Decision Transformer Model\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Stock Price\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
